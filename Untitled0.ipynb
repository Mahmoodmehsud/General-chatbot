{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdlVuw2KMFw+O1iAzYioNk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AEwL2SY_apLX"},"outputs":[],"source":["from config import *\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.vectorstores import Pinecone\n","from langchain.vectorstores import Chroma\n","from langchain.chat_models import ChatOpenAI\n","from langchain.chains import ConversationalRetrievalChain\n","from langchain.chains import RetrievalQAWithSourcesChain\n","from langchain.chains import ConversationChain\n","from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n","from langchain.chains.question_answering import load_qa_chain\n","from langchain.chains.conversation.memory import ConversationBufferMemory\n","from langchain.llms.openai import OpenAI\n","from langchain.prompts import PromptTemplate\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.embeddings import GPT4AllEmbeddings\n","\n","\n","memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"human_input\")\n","\n","template = \"\"\"You are a chatbot having a conversation with a human.\n","\n","Given the following extracted parts of a long document and a question, create a final answer.\n","\n","{context}\n","\n","{chat_history}\n","Human: {human_input}\n","Chatbot:\"\"\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"chat_history\", \"human_input\", \"context\"],\n","    template=template\n",")\n","\n","\n","def get_answer(question):\n","\n","\n","  loader = PyPDFLoader('/content/drive/My Drive/Flacon-7B_LLM/veraschat_knowledgebase/docs/CV_Report.pdf')       #Load documents\n","  data = loader.load_and_split()\n","\n","  char_text_splitter= RecursiveCharacterTextSplitter(chunk_size = 500,chunk_overlap  = 20)      #Splitting the data\n","  texts= char_text_splitter.split_documents(data)\n","\n","\n","  vectorstore = Chroma.from_documents(documents= texts, embedding=GPT4AllEmbeddings())            #Create embeddings\n","  docs = vectorstore.similarity_search(question)\n","  #print(docs)\n","\n","\n","  qa = load_qa_chain(OpenAI(temperature=0.5, openai_api_key=\"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\"), chain_type=\"stuff\", memory=memory, prompt=prompt)\n","  result = qa({\"input_documents\": docs, \"human_input\": question}, return_only_outputs=True)\n","\n","\n","  return result['output_text']"]},{"cell_type":"code","source":["get_answer('What is Tensor Flow Object Detection?')"],"metadata":{"id":"5_IraOIIbHWU"},"execution_count":null,"outputs":[]}]}